{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if os.getcwd().split('/')[-1] == 'notebooks':\n",
    "    os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CODE():\n",
    "    def __init__(self, hdf5_path = '/home/josegfer/datasets/code/output/code15.h5', \n",
    "                 metadata_path = '/home/josegfer/datasets/code/output/metadata.csv', \n",
    "                 texth5_path = '/home/josegfer/datasets/code/output/BioBERTpt_text_report.h5', \n",
    "                 val_size = 0.05, tst_size = 0.05):\n",
    "        self.hdf5_file = h5py.File(hdf5_path, 'r')\n",
    "        self.metadata = pd.read_csv(metadata_path)\n",
    "        self.texth5_file = h5py.File(texth5_path, 'r')\n",
    "\n",
    "        self.val_size = val_size\n",
    "        self.tst_size = tst_size\n",
    "\n",
    "        self.trn_metadata, self.val_metadata, self.tst_metadata = self.split()\n",
    "\n",
    "    def split(self, patient_id_col = 'patient_id'):\n",
    "        patient_ids = self.metadata[patient_id_col].unique()\n",
    "\n",
    "        num_trn = int(len(patient_ids) * (1 - self.tst_size - self.val_size))\n",
    "        num_val = int(len(patient_ids) * self.val_size)\n",
    "\n",
    "        trn_ids = set(patient_ids[:num_trn])\n",
    "        val_ids = set(patient_ids[num_trn : num_trn + num_val])\n",
    "        tst_ids = set(patient_ids[num_trn + num_val :])\n",
    "\n",
    "        trn_metadata = self.metadata.loc[self.metadata[patient_id_col].isin(trn_ids)].reset_index()\n",
    "        val_metadata = self.metadata.loc[self.metadata[patient_id_col].isin(val_ids)].reset_index()\n",
    "        tst_metadata = self.metadata.loc[self.metadata[patient_id_col].isin(tst_ids)].reset_index()\n",
    "        self.check_dataleakage(trn_metadata, val_metadata, tst_metadata)\n",
    "\n",
    "        return trn_metadata, val_metadata, tst_metadata\n",
    "\n",
    "    def check_dataleakage(self, trn_metadata, val_metadata, tst_metadata, exam_id_col = 'exam_id'):\n",
    "        trn_ids = set(trn_metadata[exam_id_col].unique())\n",
    "        val_ids = set(val_metadata[exam_id_col].unique())\n",
    "        tst_ids = set(tst_metadata[exam_id_col].unique())\n",
    "        assert (len(trn_ids.intersection(val_ids)) == 0), \"Some IDs are present in both train and validation sets.\"\n",
    "        assert (len(trn_ids.intersection(tst_ids)) == 0), \"Some IDs are present in both train and test sets.\"\n",
    "        assert (len(val_ids.intersection(tst_ids)) == 0), \"Some IDs are present in both validation and test sets.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CODEsplit(Dataset):\n",
    "    def __init__(self, database, metadata,\n",
    "                 tracing_col = 'tracings', output_col = ['1dAVb', 'RBBB', 'LBBB', 'SB', 'AF', 'ST'], textfeatures_col = 'embeddings', \n",
    "                 exam_id_col = 'exam_id', h5_idx_col = 'h5_idx'):\n",
    "        self.database = database\n",
    "        self.metadata = metadata\n",
    "\n",
    "        self.tracing_col = tracing_col\n",
    "        self.output_col = output_col\n",
    "        self.textfeatures_col = textfeatures_col\n",
    "\n",
    "        self.exam_id_col = exam_id_col\n",
    "        self.h5_idx_col = h5_idx_col\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.metadata)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {'x': self.database.hdf5_file[self.tracing_col][self.metadata[self.h5_idx_col].loc[idx]],\n",
    "                'y': self.metadata[self.output_col].loc[idx].values, \n",
    "                'exam_id': self.metadata[self.exam_id_col].loc[idx], \n",
    "                'h': self.database.texth5_file[self.textfeatures_col][self.metadata[self.h5_idx_col].loc[idx]]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = CODE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_ds = CODEsplit(db, db.trn_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_loader = DataLoader(trn_ds, batch_size = 128, shuffle = True, num_workers = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 4096, 12]),\n",
       " torch.Size([128, 6]),\n",
       " tensor([1791248, 1572419,  562516,  310531, 1071666,  632537,  500067,   61374,\n",
       "          943340, 1467955, 1051298,  968516, 1811794, 2929646,  849459, 1116246,\n",
       "          688719, 1837638, 3086851, 2872443,  336437, 1204787,  326740, 1538981,\n",
       "          676243,  478226, 1719497, 2966990,  796235, 2890693,  464035, 1357552,\n",
       "         3096695,  379880, 1714008,  414206, 2905437,  143803, 1260151, 1373160,\n",
       "         1559696, 3616596,  111887, 3202301,  262549, 1112241, 2533179, 3099585,\n",
       "           92552, 1901125,  219825,  208715, 2751324,  710433, 4218808,  508430,\n",
       "          486764, 1856067,  948831,  531820, 1663784, 1493213,  691798, 1000694,\n",
       "          673612,  536513, 1434839, 1025109,  969884, 2960163, 1058331, 1959184,\n",
       "          997269, 3789333, 1217086,  671062,  200481, 1059448, 1716340,  242548,\n",
       "          316693, 1568966, 2869263, 1465339, 2881320, 3209699,  622106, 4390434,\n",
       "         3228135,   92481,  921953, 1124331,  478221, 1320431, 3794368, 4277057,\n",
       "          670104,  149567, 1358868, 4401390, 1669183,  458660,  328308, 1445218,\n",
       "         1607393, 1221658,  540395, 3148183, 1488096,  269864,  776330, 1524922,\n",
       "         1735867,  312194, 4408729, 1375616,  801613, 1814389, 3198175,  170426,\n",
       "         3187062,   34688, 2946970, 1113516, 1294404, 4267823, 2988389,  528205]),\n",
       " torch.Size([128, 768]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for batch in (trn_loader):\n",
    "    break\n",
    "batch['x'].shape, batch['y'].shape, batch['exam_id'], batch['h'].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
