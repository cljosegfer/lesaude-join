{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if os.getcwd().split('/')[-1] == 'notebooks':\n",
    "    os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloaders.code15lb import CODElb as DS\n",
    "from dataloaders.code15lb import CODElbsplit as DSsplit\n",
    "from models.linearprob import LinearProb\n",
    "from runners.prob import Runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_label = 'linearprob'\n",
    "texth5_path = '/home/josegfer/datasets/code/output/BioBERTpt_text_report.h5'\n",
    "epochs = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class DS():\n",
    "#     def __init__(self, \n",
    "#                  metadata_path = '/home/josegfer/datasets/code/output/metadata.csv', \n",
    "#                  texth5_path = '/home/josegfer/datasets/code/output/BioBERTpt_text_report.h5', \n",
    "#                  val_size = 0.05, tst_size = 0.05):\n",
    "#         self.metadata = pd.read_csv(metadata_path)\n",
    "#         self.texth5_file = h5py.File(texth5_path, 'r')\n",
    "\n",
    "#         self.val_size = val_size\n",
    "#         self.tst_size = tst_size\n",
    "\n",
    "#         self.trn_metadata, self.val_metadata, self.tst_metadata = self.split()\n",
    "\n",
    "#     def split(self, patient_id_col = 'patient_id'):\n",
    "#         patient_ids = self.metadata[patient_id_col].unique()\n",
    "\n",
    "#         num_trn = int(len(patient_ids) * (1 - self.tst_size - self.val_size))\n",
    "#         num_val = int(len(patient_ids) * self.val_size)\n",
    "\n",
    "#         trn_ids = set(patient_ids[:num_trn])\n",
    "#         val_ids = set(patient_ids[num_trn : num_trn + num_val])\n",
    "#         tst_ids = set(patient_ids[num_trn + num_val :])\n",
    "\n",
    "#         trn_metadata = self.metadata.loc[self.metadata[patient_id_col].isin(trn_ids)].reset_index()\n",
    "#         val_metadata = self.metadata.loc[self.metadata[patient_id_col].isin(val_ids)].reset_index()\n",
    "#         tst_metadata = self.metadata.loc[self.metadata[patient_id_col].isin(tst_ids)].reset_index()\n",
    "#         self.check_dataleakage(trn_metadata, val_metadata, tst_metadata)\n",
    "\n",
    "#         return trn_metadata, val_metadata, tst_metadata\n",
    "\n",
    "#     def check_dataleakage(self, trn_metadata, val_metadata, tst_metadata, exam_id_col = 'exam_id'):\n",
    "#         trn_ids = set(trn_metadata[exam_id_col].unique())\n",
    "#         val_ids = set(val_metadata[exam_id_col].unique())\n",
    "#         tst_ids = set(tst_metadata[exam_id_col].unique())\n",
    "#         assert (len(trn_ids.intersection(val_ids)) == 0), \"Some IDs are present in both train and validation sets.\"\n",
    "#         assert (len(trn_ids.intersection(tst_ids)) == 0), \"Some IDs are present in both train and test sets.\"\n",
    "#         assert (len(val_ids.intersection(tst_ids)) == 0), \"Some IDs are present in both validation and test sets.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class DSsplit(Dataset):\n",
    "#     def __init__(self, database, metadata,\n",
    "#                  output_col = ['1dAVb', 'RBBB', 'LBBB', 'SB', 'AF', 'ST'], textfeatures_col = 'embeddings', \n",
    "#                  exam_id_col = 'exam_id', h5_idx_col = 'h5_idx'):\n",
    "#         self.database = database\n",
    "#         self.metadata = metadata\n",
    "\n",
    "#         self.output_col = output_col\n",
    "#         self.textfeatures_col = textfeatures_col\n",
    "\n",
    "#         self.exam_id_col = exam_id_col\n",
    "#         self.h5_idx_col = h5_idx_col\n",
    "    \n",
    "#     def __len__(self):\n",
    "#         return len(self.metadata)\n",
    "    \n",
    "#     def __getitem__(self, idx):\n",
    "#         return {'y': self.metadata[self.output_col].loc[idx].values, \n",
    "#                 'exam_id': self.metadata[self.exam_id_col].loc[idx], \n",
    "#                 'h': self.database.texth5_file[self.textfeatures_col][self.metadata[self.h5_idx_col].loc[idx]]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class LinearProb(nn.Module):\n",
    "#     def __init__(self, n_classes = 6):\n",
    "#         super().__init__()\n",
    "#         self.linear = nn.Linear(768, n_classes)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         logits = self.linear(x)\n",
    "#         return {'logits': logits}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "database = DS(texth5_path = texth5_path)\n",
    "model = LinearProb(n_classes = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = Runner(device = device, model = model, database = database, Split = DSsplit, model_label = model_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# draft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.data import DataLoader\n",
    "\n",
    "# model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trn_ds = DSsplit(database, database.trn_metadata)\n",
    "# trn_loader = DataLoader(trn_ds, batch_size = 128, shuffle = True, num_workers = 6)\n",
    "\n",
    "# for batch in (trn_loader):\n",
    "#     break\n",
    "# batch['y'].shape, batch['exam_id'], batch['h'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_features = batch['h'].to(device).float()\n",
    "# label = batch['y'].to(device).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logits = model.forward(text_features)\n",
    "# logits['logits'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2512 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2512/2512 [36:58<00:00,  1.13it/s]\n",
      "100%|██████████| 97/97 [00:08<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new checkpoint with val loss: 0.08965744999880643\n",
      "exporting partial model at epoch 0\n"
     ]
    }
   ],
   "source": [
    "runner.train(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97/97 [00:04<00:00, 21.99it/s]\n",
      "100%|██████████| 94/94 [00:05<00:00, 17.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exporting last model\n"
     ]
    }
   ],
   "source": [
    "runner.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
